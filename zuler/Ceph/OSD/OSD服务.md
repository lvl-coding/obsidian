# OSD服务组件
cephadm下OSD进程运行在docker内，OSD docker如下
```
CONTAINER ID   IMAGE                                     COMMAND                  CREATED          STATUS          PORTS     NAMES
d7fb9792cb92   192.168.10.92:5000/ceph                   "/usr/bin/ceph-osd -…"   3 days ago       Up 3 days                 ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd-0
06ce38864d07   192.168.10.92:5000/ceph                   "/usr/bin/ceph-osd -…"   8 days ago       Up 8 days                 ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd-1
```
## 重启OSD服务
```
$ sudo ls /etc/systemd/system/ceph-cd041c6a-fe49-11ef-b20e-131e900def78.target.wants/
ceph-cd041c6a-fe49-11ef-b20e-131e900def78@crash.shsc003.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.21.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.25.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.29.service
ceph-cd041c6a-fe49-11ef-b20e-131e900def78@mon.shsc003.service    ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.22.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.26.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.30.service
ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.19.service         ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.23.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.27.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.31.service
ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.20.service         ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.24.service  ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.28.service
$ sudo systemctl restart ceph-cd041c6a-fe49-11ef-b20e-131e900def78@osd.30
```
## 服务文件内容如下：
```
$ cat /etc/systemd/system/ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b.target.wants/ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b\@osd.1.service
# generated by cephadm
[Unit]
Description=Ceph %i for 2a4e1392-0abd-11f0-95f6-e7d0a414706b

# According to:
#   http://www.freedesktop.org/wiki/Software/systemd/NetworkTarget
# these can be removed once ceph-mon will dynamically change network
# configuration.
After=network-online.target local-fs.target time-sync.target docker.service
Wants=network-online.target local-fs.target time-sync.target
Requires=docker.service


PartOf=ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b.target
Before=ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b.target

[Service]
LimitNOFILE=1048576
LimitNPROC=1048576
EnvironmentFile=-/etc/environment
ExecStart=/bin/bash /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/%i/unit.run
ExecStop=-/bin/bash -c 'bash /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/%i/unit.stop'
ExecStopPost=-/bin/bash /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/%i/unit.poststop
KillMode=none
Restart=on-failure
RestartSec=10s
TimeoutStartSec=200
TimeoutStopSec=120
StartLimitInterval=30min
StartLimitBurst=5

[Install]
WantedBy=ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b.target
```
osd的lib文件在`/var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/osd.1/`目录下：
```
root@cluster90:/home/kvirtadm# ls /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/osd.1/ -l
total 64
lrwxrwxrwx 1 167 167  111 May  7 02:33 block -> /dev/mapper/ceph--8649f7af--ef2f--4ad3--a100--4154a42868c3-osd--block--58367491--e0bc--44bf--887e--e0338bdeb63d
-rw------- 1 167 167   37 May  7 02:33 ceph_fsid
-rw------- 1 167 167  277 Mar 27 03:50 config
-rw------- 1 167 167   37 May  7 02:33 fsid
-rw------- 1 167 167   55 May  7 02:33 keyring
-rw------- 1 167 167    6 May  7 02:33 ready
-rw------- 1 167 167    3 Mar 27 03:52 require_osd_release
-rw------- 1 167 167   10 May  7 02:33 type
-rw------- 1 167 167   38 Mar 27 03:50 unit.configured
-rw------- 1 167 167   48 Mar 27 03:50 unit.created
-rw------- 1 167 167   96 Mar 27 03:50 unit.image
-rw------- 1 167 167  367 Mar 27 03:50 unit.meta
-rw------- 1 167 167 1655 Mar 27 03:50 unit.poststop
-rw------- 1 167 167 2849 Mar 27 03:50 unit.run
-rw------- 1 167 167  330 Mar 27 03:50 unit.stop
-rw------- 1 167 167    2 May  7 02:33 whoami
```
- 当OSD的db设备和wal设备和数据盘在一起时，仅有block文件链接到osd的lvm中，否则可以看到对应的db和wal设备文件
```
lrwxrwxrwx 1 167 167  111  3月 26 20:38 block -> /dev/mapper/ceph--8f7dc658--185f--4c9f--92f9--931006203dc4-osd--block--96efd35a--75c7--477e--adca--b84d229f5e74
lrwxrwxrwx 1 167 167  108  3月 26 20:38 block.db -> /dev/mapper/ceph--63ac90b6--a7c3--4058--921f--97b4f11ba441-osd--db--1a3cbfe4--d232--430b--8160--7c16ab36a8cd
lrwxrwxrwx 1 167 167  109  3月 26 20:38 block.wal -> /dev/mapper/ceph--e7d53cc9--67a1--4e43--9905--9fa8d0d44a6d-osd--wal--0f374f73--71d5--490e--90be--895433cbcb0e
```
unit.run文件内容如下：
```bash
$ cat /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/osd.1/unit.run
set -e
/usr/bin/install -d -m0770 -o 167 -g 167 /var/run/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b
# LVM OSDs use ceph-volume lvm activate
! /usr/bin/docker rm -f ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd.1-activate 2> /dev/null
! /usr/bin/docker rm -f ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd-1-activate 2> /dev/null
/usr/bin/docker run --rm --ipc=host --stop-signal=SIGTERM --ulimit nofile=1048576 --net=host --entrypoint /usr/sbin/ceph-volume --privileged --group-add=disk --init --name ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd-1-activate -e CONTAINER_IMAGE=192.168.10.92:5000/ceph@sha256:f2a37cf25e690952a08f9ae88384aeca01a2db02ec95cdf4489cc3faf71ad2c8 -e NODE_NAME=cluster90 -e CEPH_USE_RANDOM_NONCE=1 -e CEPH_VOLUME_SKIP_RESTORECON=yes -e CEPH_VOLUME_DEBUG=1 -v /var/run/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b:/var/run/ceph:z -v /var/log/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b:/var/log/ceph:z -v /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/crash:/var/lib/ceph/crash:z -v /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/osd.1:/var/lib/ceph/osd/ceph-1:z -v /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/osd.1/config:/etc/ceph/ceph.conf:z -v /dev:/dev -v /run/udev:/run/udev -v /sys:/sys -v /run/lvm:/run/lvm -v /run/lock/lvm:/run/lock/lvm -v /:/rootfs 192.168.10.92:5000/ceph@sha256:f2a37cf25e690952a08f9ae88384aeca01a2db02ec95cdf4489cc3faf71ad2c8 activate --osd-id 1 --osd-uuid 58367491-e0bc-44bf-887e-e0338bdeb63d --no-systemd --no-tmpfs
# osd.1
! /usr/bin/docker rm -f ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd.1 2> /dev/null
! /usr/bin/docker rm -f ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd-1 2> /dev/null
/usr/bin/docker run --rm --ipc=host --stop-signal=SIGTERM --ulimit nofile=1048576 --net=host --entrypoint /usr/bin/ceph-osd --privileged --group-add=disk --init --name ceph-2a4e1392-0abd-11f0-95f6-e7d0a414706b-osd-1 --pids-limit=0 -e CONTAINER_IMAGE=192.168.10.92:5000/ceph@sha256:f2a37cf25e690952a08f9ae88384aeca01a2db02ec95cdf4489cc3faf71ad2c8 -e NODE_NAME=cluster90 -e CEPH_USE_RANDOM_NONCE=1 -e TCMALLOC_MAX_TOTAL_THREAD_CACHE_BYTES=134217728 -v /var/run/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b:/var/run/ceph:z -v /var/log/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b:/var/log/ceph:z -v /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/crash:/var/lib/ceph/crash:z -v /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/osd.1:/var/lib/ceph/osd/ceph-1:z -v /var/lib/ceph/2a4e1392-0abd-11f0-95f6-e7d0a414706b/osd.1/config:/etc/ceph/ceph.conf:z -v /dev:/dev -v /run/udev:/run/udev -v /sys:/sys -v /run/lvm:/run/lvm -v /run/lock/lvm:/run/lock/lvm -v /:/rootfs 192.168.10.92:5000/ceph@sha256:f2a37cf25e690952a08f9ae88384aeca01a2db02ec95cdf4489cc3faf71ad2c8 -n osd.1 -f --setuser ceph --setgroup ceph --default-log-to-file=false --default-log-to-stderr=true '--default-log-stderr-prefix=debug '
```
脚本说明：
- 如果有旧的执行activate操作的docker容器则删除
- 使用ceph-volume activate激活OSD
```
$ ceph-volume activate --osd-id 1 --osd-uuid 58367491-e0bc-44bf-887e-e0338bdeb63d --no-systemd --no-tmpfs
```
- 如果有旧的，则清理残留的OSD容器
- 执行ceph-osd命令启动OSD服务进程
```
$ ceph-osd -n osd.1 -f --setuser ceph --setgroup ceph --default-log-to-file=false --default-log-to-stderr=true '--default-log-stderr-prefix=debug '
```
[[zuler/Ceph/OSD/ceph-volume|ceph-volume]]
